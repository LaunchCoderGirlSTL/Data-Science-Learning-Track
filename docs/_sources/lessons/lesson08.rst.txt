Lesson 8: Linear Regression Part 1
==================================

Learning Objectives
-------------------

* The purpose of machine learning: learning model h(x) with parameters theta
* Definition of h(x) for linear regression
* Definition of sum of squared error cost function (linear regression cost function)
* Minimizing the linear regression cost function
* Gradient Descent Algorithm: Learning Rate
* Gradient Descent Algorithm: Simultaneous update of theta
* Gradient Descent Algorithm: Partial derivative of theta
* Tuning alpha: convergence versus divergence of gradient descent
* Batch Gradient Descent

Lectures (Videos and Readings)
------------------------------

Complete the readings and videos in the `Linear Regression with One Variable  <https://www.coursera.org/learn/machine-learning>`_ module of Coursera

In Class Assignment
-------------------

We will be introducing the scikit-learn (or sklearn) python module, and using it to help learn about Linear Regression.

Quizzes
-------

Complete the quizzes in the `Linear Regression with One Variable <https://www.coursera.org/learn/machine-learning>`_ module of Coursera

Homework
--------