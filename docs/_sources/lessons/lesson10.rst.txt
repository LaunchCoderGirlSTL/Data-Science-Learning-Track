Lesson 10: Linear Regression Part 2
===================================

Learning Objectives
-------------------

* Understanding how multiple features can inform your prediction target
* Gradient descent for multiple variables: simultaneous update of partial derivative of J(theta)
* The reasoning behind feature scaling
* Mean normalization
* Checking the Gradient Descent: automatic convergence test
* Checking the Gradient Descent: adjusting alpha
* Understanding polynomial regression
* Understanding the runtime of normal equation and gradient descent
* Knowing when to use gradient descent and when to use normal equation

Lectures (Videos and Readings)
------------------------------

In Class Assignment
-------------------

Quizzes
-------

Homework
--------